{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca22115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# MNIST DIGIT CLASSIFIER (PyTorch)\n",
    "# -----------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import gradio as gr\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "print(f'Using device: {device}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df2a9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. LOAD DATA\n",
    "# Transforms are preprocessing steps that get applied automatically to every image\n",
    "# you load from a dataset. \n",
    "# Think of transforms as a recipe that says:\n",
    "\n",
    "# “Every time you give me an image, do X, then Y, then Z to it.”\n",
    "# “For every MNIST image: convert it to a PyTorch tensor.\n",
    "# MNIST images come in as PIL images (Python Imaging Library).\n",
    "\n",
    "# But your neural network expects tensors.\n",
    "# -----------------------------\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a123ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform_train,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de572723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transform_test,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87def014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training dataset: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Make DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "unique_labels = sorted(set(train_dataset.targets.tolist()))\n",
    "print('Unique labels in training dataset:', unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091eb8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. DEFINE NEURAL NETWORK\n",
    "# -----------------------------\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.norm = nn.LayerNorm(128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.norm(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9d13bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=12544, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. DEFINE CNN MODEL (better/alternate method that uses a convolutional neural network)\n",
    "# The reason that we would want to use a CNN over a NN is that CNNs are just better at image related tasks, so we should expect better performance from this model.\n",
    "# -----------------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),)\n",
    "        self.fc = nn.Sequential(nn.Linear(64 * 14 * 14, 128), nn.ReLU(), nn.Linear(128, 10))\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95d12046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. LOSS FUNCTION + OPTIMIZER\n",
    "# -----------------------------\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d32ff29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/l2b9qlms07g2ky4_nwq8kxjh0000gn/T/ipykernel_12724/1209600713.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "Epoch 1/35:   0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/l2b9qlms07g2ky4_nwq8kxjh0000gn/T/ipykernel_12724/1209600713.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "Epoch 1/35: 100%|██████████| 938/938 [00:07<00:00, 123.31it/s, loss=0.105] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35, Avg Loss: 0.2952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/35: 100%|██████████| 938/938 [00:09<00:00, 103.39it/s, loss=0.2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/35, Avg Loss: 0.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/35: 100%|██████████| 938/938 [00:09<00:00, 103.91it/s, loss=0.0326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35, Avg Loss: 0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/35: 100%|██████████| 938/938 [00:06<00:00, 141.94it/s, loss=0.0222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35, Avg Loss: 0.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/35: 100%|██████████| 938/938 [00:09<00:00, 96.38it/s, loss=0.0653]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/35, Avg Loss: 0.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/35: 100%|██████████| 938/938 [00:12<00:00, 73.85it/s, loss=0.0273] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/35, Avg Loss: 0.0716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/35: 100%|██████████| 938/938 [00:14<00:00, 66.26it/s, loss=0.172]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/35, Avg Loss: 0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/35: 100%|██████████| 938/938 [00:13<00:00, 68.57it/s, loss=0.196]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/35, Avg Loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/35: 100%|██████████| 938/938 [00:11<00:00, 84.47it/s, loss=0.0721]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/35, Avg Loss: 0.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/35: 100%|██████████| 938/938 [00:07<00:00, 122.18it/s, loss=0.0373] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/35, Avg Loss: 0.0522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/35: 100%|██████████| 938/938 [00:06<00:00, 150.70it/s, loss=0.0553] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/35, Avg Loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/35: 100%|██████████| 938/938 [00:05<00:00, 156.36it/s, loss=0.0736] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/35, Avg Loss: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/35: 100%|██████████| 938/938 [00:05<00:00, 160.26it/s, loss=0.0328] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/35, Avg Loss: 0.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/35: 100%|██████████| 938/938 [00:05<00:00, 159.58it/s, loss=0.0163] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/35, Avg Loss: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/35: 100%|██████████| 938/938 [00:05<00:00, 159.90it/s, loss=0.0244] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/35, Avg Loss: 0.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/35: 100%|██████████| 938/938 [00:05<00:00, 156.69it/s, loss=0.0624] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/35, Avg Loss: 0.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/35: 100%|██████████| 938/938 [00:05<00:00, 160.38it/s, loss=0.0436] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/35, Avg Loss: 0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/35: 100%|██████████| 938/938 [00:05<00:00, 159.39it/s, loss=0.0708] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/35, Avg Loss: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/35: 100%|██████████| 938/938 [00:06<00:00, 152.76it/s, loss=0.018]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/35, Avg Loss: 0.0320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/35: 100%|██████████| 938/938 [00:10<00:00, 87.23it/s, loss=0.00163] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/35, Avg Loss: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/35: 100%|██████████| 938/938 [00:06<00:00, 135.63it/s, loss=0.0351]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/35, Avg Loss: 0.0297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/35: 100%|██████████| 938/938 [00:06<00:00, 139.99it/s, loss=0.0463]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/35, Avg Loss: 0.0279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/35: 100%|██████████| 938/938 [00:06<00:00, 139.28it/s, loss=0.158]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/35, Avg Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/35: 100%|██████████| 938/938 [00:06<00:00, 137.94it/s, loss=0.00252] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/35, Avg Loss: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/35: 100%|██████████| 938/938 [00:06<00:00, 138.52it/s, loss=0.00423] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/35, Avg Loss: 0.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/35: 100%|██████████| 938/938 [00:06<00:00, 137.19it/s, loss=0.0626]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35, Avg Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/35: 100%|██████████| 938/938 [00:06<00:00, 144.32it/s, loss=0.00217] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/35, Avg Loss: 0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/35: 100%|██████████| 938/938 [00:06<00:00, 145.20it/s, loss=0.0019]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/35, Avg Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/35: 100%|██████████| 938/938 [00:09<00:00, 101.76it/s, loss=0.00344] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/35, Avg Loss: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/35: 100%|██████████| 938/938 [00:08<00:00, 108.89it/s, loss=0.0171]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35, Avg Loss: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/35: 100%|██████████| 938/938 [00:08<00:00, 114.23it/s, loss=0.00886] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/35, Avg Loss: 0.0203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/35: 100%|██████████| 938/938 [00:09<00:00, 94.30it/s, loss=0.00898]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/35, Avg Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/35: 100%|██████████| 938/938 [00:08<00:00, 114.27it/s, loss=0.0052]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/35, Avg Loss: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/35: 100%|██████████| 938/938 [00:11<00:00, 84.31it/s, loss=0.00403]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/35, Avg Loss: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/35: 100%|██████████| 938/938 [00:16<00:00, 55.73it/s, loss=0.0427]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Avg Loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. TRAINING LOOP\n",
    "# -----------------------------\n",
    "\n",
    "epochs = 35\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59c6e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.20%\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. EVALUATION\n",
    "# -----------------------------\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b038ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. TEST SINGLE PREDICTION\n",
    "# -----------------------------\n",
    "# Gradio sketchpad returns a full-color NumPy array (H,W,3).\n",
    "# MNIST images are grayscale (1x28x28) and normalized.\n",
    "# This preprocessing converts user drawings into MNIST format.\n",
    "# -----------------------------\n",
    "\n",
    "# MNIST normalization values:\n",
    "MNIST_MEAN = (0.1307,)\n",
    "MNIST_STD  = (0.3081,)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"Convert Gradio Sketchpad output to a normalized 1x28x28 tensor.\"\"\"\n",
    "\n",
    "    # Gradio may pass {'composite': array}\n",
    "    if isinstance(image, dict) and \"composite\" in image:\n",
    "        image = image[\"composite\"]\n",
    "\n",
    "    # Define preprocessing pipeline\n",
    "    sketch_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),                      # NumPy → PIL\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to 1 channel\n",
    "        transforms.Resize((28, 28)),                  # Match MNIST input\n",
    "        transforms.Lambda(lambda img: ImageOps.invert(img)),  \n",
    "        transforms.ToTensor(),                        # → (1, 28, 28), values in [0,1]\n",
    "        transforms.Normalize(MNIST_MEAN, MNIST_STD),  # Match MNIST training normalization\n",
    "    ])\n",
    "\n",
    "    tensor = sketch_transform(image)                  # Shape: (1, 28, 28)\n",
    "    tensor = tensor.unsqueeze(0)                      # Shape: (1, 1, 28, 28)\n",
    "    return tensor.to(device)                          # Move to same device as model\n",
    "\n",
    "\n",
    "def predict_digit(image):\n",
    "    \"\"\"Take raw Sketchpad input → return predicted digit + confidence.\"\"\"\n",
    "    \n",
    "    if image is None:\n",
    "        return \"Draw something!\"\n",
    "\n",
    "    # Convert to model input format\n",
    "    input_tensor = preprocess_image(image)\n",
    "\n",
    "    # Ensure model is in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        \n",
    "        # turn logits into probabilities\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        # predicted class index\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "        # confidence of that class\n",
    "        confidence = probs[0, predicted_class].item()\n",
    "\n",
    "    # return nicely formatted output\n",
    "    return f\"{predicted_class}  ({confidence * 100:.2f}% confidence)\"\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# GRADIO UI\n",
    "# -----------------------------\n",
    "interface = gr.Interface(\n",
    "    fn=predict_digit,\n",
    "    inputs=gr.Sketchpad(label=\"Draw Here\"),\n",
    "    outputs=\"label\",\n",
    "    live=False,\n",
    ")\n",
    "\n",
    "interface.queue().launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
