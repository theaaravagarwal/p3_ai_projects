{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca22115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# MNIST DIGIT CLASSIFIER (PyTorch)\n",
    "# -----------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2a9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. LOAD DATA\n",
    "# Transforms are preprocessing steps that get applied automatically to every image\n",
    "# you load from a dataset. \n",
    "# Think of transforms as a recipe that says:\n",
    "\n",
    "# “Every time you give me an image, do X, then Y, then Z to it.”\n",
    "# “For every MNIST image: convert it to a PyTorch tensor.\n",
    "# MNIST images come in as PIL images (Python Imaging Library).\n",
    "\n",
    "# But your neural network expects tensors.\n",
    "# -----------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7abf5ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset (MNIST)\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de572723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87def014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training dataset: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Make DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "unique_labels = sorted(set(train_dataset.targets.tolist()))\n",
    "print('Unique labels in training dataset:', unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "091eb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. DEFINE NEURAL NETWORK\n",
    "# Neural Network with 1 hidden layer of 128 neurons\n",
    "# -----------------------------\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128);\n",
    "        self.fc2 = nn.Linear(128, 10);\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten image: (batch, 1, 28, 28) → (batch, 784)\n",
    "        x = x.view(-1, 28*28);\n",
    "        x = torch.relu(self.fc1(x));\n",
    "        x = self.fc2(x);\n",
    "        return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138089f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu');\n",
    "model = SimpleNN().to(device);\n",
    "print(f'Using device: {device}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d12046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. LOSS FUNCTION + OPTIMIZER\n",
    "# -----------------------------\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d32ff29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Avg Loss: 0.0062\n",
      "Epoch 2/20, Avg Loss: 0.0047\n",
      "Epoch 2/20, Avg Loss: 0.0047\n",
      "Epoch 3/20, Avg Loss: 0.0014\n",
      "Epoch 3/20, Avg Loss: 0.0014\n",
      "Epoch 4/20, Avg Loss: 0.0040\n",
      "Epoch 4/20, Avg Loss: 0.0040\n",
      "Epoch 5/20, Avg Loss: 0.0018\n",
      "Epoch 5/20, Avg Loss: 0.0018\n",
      "Epoch 6/20, Avg Loss: 0.0004\n",
      "Epoch 6/20, Avg Loss: 0.0004\n",
      "Epoch 7/20, Avg Loss: 0.0002\n",
      "Epoch 7/20, Avg Loss: 0.0002\n",
      "Epoch 8/20, Avg Loss: 0.0002\n",
      "Epoch 8/20, Avg Loss: 0.0002\n",
      "Epoch 9/20, Avg Loss: 0.0021\n",
      "Epoch 9/20, Avg Loss: 0.0021\n",
      "Epoch 10/20, Avg Loss: 0.0102\n",
      "Epoch 10/20, Avg Loss: 0.0102\n",
      "Epoch 11/20, Avg Loss: 0.0007\n",
      "Epoch 11/20, Avg Loss: 0.0007\n",
      "Epoch 12/20, Avg Loss: 0.0021\n",
      "Epoch 12/20, Avg Loss: 0.0021\n",
      "Epoch 13/20, Avg Loss: 0.0044\n",
      "Epoch 13/20, Avg Loss: 0.0044\n",
      "Epoch 14/20, Avg Loss: 0.0022\n",
      "Epoch 14/20, Avg Loss: 0.0022\n",
      "Epoch 15/20, Avg Loss: 0.0030\n",
      "Epoch 15/20, Avg Loss: 0.0030\n",
      "Epoch 16/20, Avg Loss: 0.0013\n",
      "Epoch 16/20, Avg Loss: 0.0013\n",
      "Epoch 17/20, Avg Loss: 0.0041\n",
      "Epoch 17/20, Avg Loss: 0.0041\n",
      "Epoch 18/20, Avg Loss: 0.0020\n",
      "Epoch 18/20, Avg Loss: 0.0020\n",
      "Epoch 19/20, Avg Loss: 0.0005\n",
      "Epoch 19/20, Avg Loss: 0.0005\n",
      "Epoch 20/20, Avg Loss: 0.0001\n",
      "Epoch 20/20, Avg Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. TRAINING LOOP\n",
    "# -----------------------------\n",
    "\n",
    "epochs = 20;\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device);\n",
    "        labels = labels.to(device);\n",
    "        \n",
    "        optimizer.zero_grad();\n",
    "\n",
    "        outputs = model(images);\n",
    "\n",
    "        loss = criterion(outputs, labels);\n",
    "\n",
    "        loss.backward(); #backprop\n",
    "\n",
    "        optimizer.step(); #update the weights based on the gradients\n",
    "\n",
    "        total_loss+=loss.item()*images.size(0); #this is to get the total loss for the epoch\n",
    "\n",
    "    avg_loss = total_loss/len(train_loader.dataset) #avg loss for that epoch\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Avg Loss: {avg_loss:.4f}\") #print above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.36%\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. EVALUATION\n",
    "# -----------------------------\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b038ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label:     7\n",
      "Predicted label:  7\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. TEST SINGLE PREDICTION\n",
    "# -----------------------------\n",
    "# -----------------------------\n",
    "# 6. TEST SINGLE PREDICTION\n",
    "# -----------------------------\n",
    "# ------------------------------\n",
    "# Gradio Sketchpad gives you:\n",
    "\n",
    "# * a full-color NumPy array\n",
    "\n",
    "# * black digit on white background\n",
    "\n",
    "# * large resolution\n",
    "\n",
    "# * no consistent scale\n",
    "#\n",
    "# Hence the preprocessing\n",
    "# ------------------------------\n",
    "\n",
    "def preprocess_image(image):\n",
    "    sketch_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                      # NumPy → PIL\n",
    "    transforms.Grayscale(),                       # ensure 1 channel\n",
    "    transforms.Resize((28, 28)),                  # 28x28 like MNIST\n",
    "    transforms.Lambda(lambda img: ImageOps.invert(img)),  # invert colors\n",
    "    transforms.ToTensor(),                        # → tensor, shape (1,28,28), values in [0,1]\n",
    "    ])\n",
    "    # Gradio Sketchpad sometimes passes a dict with 'composite'\n",
    "    if isinstance(image, dict):\n",
    "        image = image['composite']   # this is a NumPy array\n",
    "    \n",
    "    # Apply the preprocessing transform\n",
    "    img_tensor = sketch_transform(image)  # (1, 28, 28)\n",
    "    \n",
    "    # Add batch dimension → (1, 1, 28, 28)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def predict_digit(image):\n",
    "    # --- STEP 1: CHECK IF SOMETHING HAS BEEN DRAWN ---\n",
    "    if image is None: return \"Draw something!\"\n",
    "\n",
    "    # --- STEP 2: PREPROCESS THE IMAGE ---\n",
    "    img_tensor = preprocess_image(image)\n",
    "    \n",
    "    # --- STEP 3: RUN THE MODEL ---\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img_tensor)\n",
    "        \n",
    "        # Get the index of the highest score (the predicted digit)\n",
    "        predicted_digit = torch.argmax(prediction).item()\n",
    "        \n",
    "    return str(predicted_digit)\n",
    "\n",
    "# UI Setup\n",
    "interface = gr.Interface(fn=predict_digit, inputs=gr.Sketchpad(label=\"Draw Here\"), outputs=\"label\")\n",
    "interface.queue().launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
